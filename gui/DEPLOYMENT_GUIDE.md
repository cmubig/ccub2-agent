# CCUB2 Agent GUI - Deployment & Testing Guide

## ğŸ‰ Integration Complete!

The CCUB2 GUI is now fully integrated with the real CCUB2 pipeline:
- âœ… Real T2I generation (SDXL, FLUX, SD3.5, Gemini)
- âœ… Real VLM detection (Qwen3-VL-8B)
- âœ… Real CLIP RAG (image similarity search)
- âœ… Real Reference Selector (keyword matching)
- âœ… Real I2I editing (Qwen, FLUX, SDXL, SD3.5)
- âœ… Real-time WebSocket updates
- âœ… GPU memory management

---

## ğŸ“‹ Prerequisites

### 1. Data Setup
Ensure you have initialized data for at least one country:

```bash
# Check if Korea data exists
ls -la /home/chans/ccub2-agent/data/clip_index/korea
ls -la /home/chans/ccub2-agent/data/cultural_index/korea
ls -la /home/chans/ccub2-agent/data/country_packs/korea/images

# If not, run initialization:
python scripts/01_setup/init_dataset.py --country korea
```

### 2. Python Dependencies
Install backend dependencies:

```bash
cd /home/chans/ccub2-agent/gui/backend

# Install requirements
pip install -r requirements.txt

# Verify PyTorch CUDA availability
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

### 3. Node.js Dependencies
Already installed (from earlier setup).

---

## ğŸš€ Starting the System

### Terminal 1: Backend (FastAPI)

```bash
cd /home/chans/ccub2-agent/gui/backend
python main.py
```

**Expected output:**
```
INFO:     Started server process
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000
```

**Check health:**
```bash
curl http://localhost:8000/health
# Should return: {"status":"healthy"}
```

### Terminal 2: Frontend (Next.js)

```bash
cd /home/chans/ccub2-agent/gui/frontend
npm run dev
```

**Expected output:**
```
â–² Next.js 14.1.0
- Local:        http://localhost:3000
âœ“ Ready in 1019ms
```

### Terminal 3: SSH Port Forwarding (Local Machine)

On your **local computer**, connect with port forwarding:

```bash
ssh -L 3000:localhost:3000 -L 8000:localhost:8000 chans@big-rodin1
```

Then open in browser: **http://localhost:3000**

---

## ğŸ§ª Testing the Pipeline

### Test 1: Basic Connection

1. Open **http://localhost:3000** in browser
2. You should see:
   - âœ… Node-based pipeline visualization
   - âœ… "Connected" indicator (green dot)
   - âœ… Configuration panel on the right

### Test 2: Simple Pipeline Run

1. **Configure:**
   - Prompt: "A Korean woman in traditional hanbok"
   - Country: Korea
   - Category: Traditional Clothing
   - T2I Model: SDXL (fastest for testing)
   - I2I Model: Qwen

2. **Click "ğŸš€ Start Pipeline"**

3. **Watch the nodes light up:**
   - Input â¸ â†’ âœ…
   - T2I Gen â¸ â†’ ğŸ”„ â†’ âœ…
   - VLM Detector â¸ â†’ ğŸ”„ â†’ âœ…
   - Reference Selector â¸ â†’ ğŸ”„ â†’ âœ…
   - I2I Editor â¸ â†’ ğŸ”„ â†’ âœ…

4. **Check the logs** (Backend terminal):
   ```
   INFO - Creating T2I adapter: sdxl
   INFO - âœ“ T2I generation complete: .../step_0_initial.png
   INFO - Getting VLM detector...
   INFO - âœ“ VLM detection complete: Cultural=4.2, Prompt=6.1
   INFO - Getting CLIP RAG...
   INFO - âœ“ Selected reference: palace.jpg (score: 1.165)
   INFO - Getting I2I adapter: qwen
   INFO - âœ“ I2I editing complete: .../step_1_edited.png
   INFO - âœ“ Pipeline complete! Final score: 7.8/10
   ```

5. **Check the results:**
   - Click on nodes to see details
   - VLM Detector node should show REAL scores (not 4.2!)
   - Output node shows final cultural score

### Test 3: Verify Real Data

**Check generated images:**
```bash
cd /home/chans/ccub2-agent/gui/outputs
ls -la */  # See all session directories
```

You should see:
- `step_0_initial.png` - T2I generated
- `step_1_edited.png` - I2I edited

**View an image:**
```bash
# Find latest session
LATEST=$(ls -td */ | head -1)
ls -la $LATEST
```

### Test 4: Check VLM Scores are Real

Run pipeline twice with same prompt:
1. First run: Note the cultural score (e.g., 4.5)
2. Second run: Score should be DIFFERENT (not always 4.2)
3. This confirms VLM is actually analyzing images!

### Test 5: Iteration Loop

1. Configure with low target score: Target Score = 9.0
2. Max Iterations = 3
3. Run pipeline
4. Watch it iterate:
   - Iteration 1: T2I â†’ VLM â†’ I2I
   - Iteration 2: VLM â†’ I2I (if score < 9.0)
   - Iteration 3: VLM â†’ I2I (if still < 9.0)
5. Check final score improves across iterations

---

## ğŸ› Troubleshooting

### Problem: Backend won't start

**Error: `ModuleNotFoundError: No module named 'ccub2_agent'`**

Solution:
```bash
cd /home/chans/ccub2-agent/gui/backend
export PYTHONPATH=/home/chans/ccub2-agent:$PYTHONPATH
python main.py
```

**Error: `faiss not found`**

Solution:
```bash
pip install faiss-cpu
# Or if CUDA available:
pip install faiss-gpu
```

### Problem: Frontend shows "Disconnected"

1. Check backend is running: `curl http://localhost:8000/health`
2. Check WebSocket port: `curl http://localhost:8000/`
3. Check browser console for WebSocket errors

### Problem: VLM loading fails

**Error: `CUDA out of memory`**

Solution - Use 4-bit quantization (should be default):
```python
# In config panel:
âœ… Use 4-bit quantization (saves VRAM)
```

Or reduce batch size / use smaller model.

### Problem: Models downloading slowly

Models are cached in `/scratch/chans/hf_cache`. First run will download:
- Qwen3-VL-8B-Instruct (~16GB)
- SDXL (~7GB)
- Qwen-Image-Edit (~10GB)

Subsequent runs use cached models.

### Problem: "No suitable reference found"

Check CLIP index exists:
```bash
ls -la /home/chans/ccub2-agent/data/clip_index/korea/
# Should have: clip.index, clip_metadata.jsonl, clip_config.json
```

If missing, rebuild:
```bash
python scripts/indexing/build_clip_image_index.py --country korea
```

---

## ğŸ“Š Performance Expectations

| Operation | Time | VRAM Usage |
|-----------|------|------------|
| T2I (SDXL) | 5-15s | ~8GB |
| VLM Detection | 3-8s | ~6GB (4-bit) |
| CLIP RAG Search | 0.5-2s | ~2GB |
| Reference Selection | 0.3-1s | Minimal |
| I2I (Qwen) | 10-30s | ~10GB |
| **Total (1 iteration)** | **20-60s** | **~10-12GB peak** |

With 3 iterations: 40-120s total

---

## ğŸ” Monitoring

### GPU Usage

```bash
watch -n 1 nvidia-smi
```

Watch for:
- Memory usage spikes during VLM/I2I
- Memory cleanup after pipeline completes
- Temperature (should stay < 85Â°C)

### Backend Logs

Real-time logs show:
```
INFO - Creating T2I adapter: sdxl
INFO - âœ“ T2I generation complete
INFO - Getting VLM detector...
INFO - âœ“ VLM detection complete: Cultural=4.5, Prompt=6.8
INFO - âœ“ Selected reference: palace.jpg (score: 1.165)
INFO - âœ“ I2I editing complete
INFO - Cleaning up GPU memory...
INFO - âœ“ GPU memory cleared
```

### Frontend Console

Open browser DevTools (F12) â†’ Console

Watch for:
```
WebSocket connected
WebSocket message: {type: "node_update", node_id: "t2i_generator", status: "processing"}
WebSocket message: {type: "node_update", node_id: "t2i_generator", status: "completed"}
```

---

## ğŸ¨ Known Limitations

1. **Image Display**: Base64 images sent via WebSocket (1-2MB each)
   - May be slow on poor connections
   - Future: Use static file serving

2. **Progress Callbacks**: I2I editing shows indeterminate progress
   - Most models don't expose per-step callbacks
   - Future: Add progress polling for Diffusers models

3. **Model Caching**: First run downloads models
   - ~30-40GB total for all models
   - Cached in `/scratch/chans/hf_cache`

4. **Concurrent Runs**: Only one pipeline at a time
   - GPU memory constraints
   - Future: Queue system

---

## ğŸš€ Next Steps

### Phase 1: Immediate (Done! âœ…)
- âœ… Backend integration with real CCUB2
- âœ… WebSocket real-time updates
- âœ… All nodes use real models

### Phase 2: Enhancements (Optional)
- [ ] Add image thumbnails to nodes
- [ ] Click node â†’ view full image modal
- [ ] Progress bar for I2I diffusion steps
- [ ] History viewer (past runs)
- [ ] Export results (images + scores)

### Phase 3: Advanced (Future)
- [ ] Multi-user support
- [ ] Pipeline queue system
- [ ] Model selection per run
- [ ] Parameter tuning UI
- [ ] Agent job creation UI

---

## ğŸ“ File Structure Summary

```
gui/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI entry point
â”‚   â”œâ”€â”€ config.py            # Paths & settings âœ… NEW
â”‚   â”œâ”€â”€ requirements.txt     # Dependencies âœ… UPDATED
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ pipeline.py      # Pipeline endpoints
â”‚   â”‚   â”œâ”€â”€ nodes.py         # Node endpoints
â”‚   â”‚   â””â”€â”€ websocket.py     # WebSocket manager
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ pipeline.py      # Pipeline data models
â”‚   â”‚   â””â”€â”€ node.py          # Node data models
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ component_manager.py  # CCUB2 components âœ… NEW
â”‚       â””â”€â”€ pipeline_runner.py    # Pipeline execution âœ… UPDATED
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ app/
    â”‚   â”‚   â”œâ”€â”€ page.tsx         # Main page
    â”‚   â”‚   â””â”€â”€ globals.css      # Dark monotone styles
    â”‚   â”œâ”€â”€ components/
    â”‚   â”‚   â”œâ”€â”€ Pipeline/
    â”‚   â”‚   â”‚   â””â”€â”€ PipelineCanvas.tsx  # React Flow canvas
    â”‚   â”‚   â”œâ”€â”€ Nodes/
    â”‚   â”‚   â”‚   â”œâ”€â”€ BaseNode.tsx
    â”‚   â”‚   â”‚   â”œâ”€â”€ VLMDetectorNode.tsx
    â”‚   â”‚   â”‚   â””â”€â”€ I2IEditorNode.tsx
    â”‚   â”‚   â””â”€â”€ Panels/
    â”‚   â”‚       â”œâ”€â”€ ConfigPanel.tsx
    â”‚   â”‚       â””â”€â”€ NodeDetailPanel.tsx
    â”‚   â”œâ”€â”€ hooks/
    â”‚   â”‚   â””â”€â”€ useWebSocket.ts   # WebSocket hook
    â”‚   â””â”€â”€ lib/
    â”‚       â”œâ”€â”€ api.ts            # API client
    â”‚       â””â”€â”€ types.ts          # TypeScript types
    â””â”€â”€ package.json
```

---

## âœ… Success Criteria

You'll know it's working when:

1. âœ… Nodes light up in sequence (not all at once)
2. âœ… VLM scores are different each run (not always 4.2)
3. âœ… Generated images exist in `gui/outputs/*/`
4. âœ… Final score improves across iterations
5. âœ… Backend logs show real model loading
6. âœ… GPU memory usage spikes during execution
7. âœ… Pipeline completes without errors

---

## ğŸ“§ Support

If you encounter issues:

1. Check logs (backend terminal)
2. Check browser console (F12)
3. Verify data/indexes exist
4. Check GPU memory (nvidia-smi)
5. Restart backend & frontend

---

**Happy Testing! ğŸ‰**

The CCUB2 GUI is now running with REAL models!
